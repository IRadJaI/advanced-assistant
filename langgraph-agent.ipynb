{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5c6e0c",
   "metadata": {},
   "source": [
    "## Подбор еды с помощью LangGraph Agentic Workflow\n",
    "\n",
    "Рассмотрим сценарий, когда нам нужно подобрать меню для пользователя в некотором ресторане, таким образом, чтобы вино подходило к основному блюду. Для этой задачи можно использовать типовой процесс из реальной жизни, в котором участвуют:\n",
    "* Хостесс для выяснения первоначальных предпочтений посетителя\n",
    "* Официант, знакомый с меню ресторана, и умеющий отвечать на вопросы по блюдам\n",
    "* Сомелье, умеющий подбирать подходящее вино\n",
    "\n",
    "Для каждой из этих задач можем использовать отдельного агента со своими навыками (инструментами) и/или RAG-базой знаний.\n",
    "\n",
    "Для создания агентов используем код из [рассмотренного ранее примера](advanced-assistant.ipynb). Для начала - несколько полезных функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b419b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "if os.name == 'nt':\n",
    "    os.environ[\"GRPC_POLL_STRATEGY\"] = \"poll\"\n",
    "    import asyncio\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "def fread(fn):\n",
    "    with open(fn, encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def printx(x):\n",
    "    display(Markdown(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97616369",
   "metadata": {},
   "source": [
    "## Авторизация\n",
    "\n",
    "Для работы с языковыми моделями нам понадобится авторизоваться в Yandex Cloud. Это можно сделать несколькими способами:\n",
    "\n",
    "* через iam-токен. Для получения iam-токена необходимо создать авторизованный ключ доступа к сервисному аккаунту, и знать `service_accound_id`, `key_id` и `private_key`. Скачайте файл с ключами доступа `authorized_key.json`, и добавьте к нему поле `folder_id`\n",
    "* **[рекомендованный способ]** через ключ `api_key` для сервисного аккаунта, имеющего права на доступ к модели, и `folder_id`. Мы предполагаем, что соответствующие значения хранятся в секретах Datasphere или в переменных окружения. Если вы используете набор переменных окружения в файле `.env` - запустите следующую ячейку для их загрузки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd9ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IAM Token Auth with folder_id=b1gst3c7cskk2big5fqn\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from util.iam_auth import get_iam\n",
    "\n",
    "if os.path.exists('authorized_key.json'):\n",
    "    with open('authorized_key.json') as f:\n",
    "        auth_key = json.load(f)\n",
    "\n",
    "    api_key = get_iam(auth_key['service_account_id'],auth_key['id'],auth_key['private_key'])\n",
    "    folder_id = auth_key['folder_id']\n",
    "    print(f\"Using IAM Token Auth with folder_id={folder_id}\")\n",
    "else:\n",
    "    folder_id = None\n",
    "\n",
    "if folder_id is None:\n",
    "    folder_id = os.environ[\"folder_id\"]\n",
    "    api_key = os.environ[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7db022",
   "metadata": {},
   "source": [
    "Создадим какую-нибудь модель из Foundation Models и убедимся, что она кое-что знает про вина. \n",
    "\n",
    "> ВНИМАНИЕ: Для правильной работы необходимо передать `folder_id` в параметр `project` при создании объекта OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547aadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI,AsyncOpenAI\n",
    "\n",
    "model = f\"gpt://{folder_id}/yandexgpt/rc\"\n",
    "model = f\"gpt://{folder_id}/gemma-3-27b-it/latest\"\n",
    "model = f\"gpt://{folder_id}/gpt-oss-120b/latest\"\n",
    "model = f\"gpt://{folder_id}/qwen3-235b-a22b-fp8/latest\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://rest-assistant.api.cloud.yandex.net/v1\",\n",
    "    api_key=api_key,\n",
    "    project=folder_id\n",
    ")\n",
    "\n",
    "aclient = AsyncOpenAI(\n",
    "    base_url=\"https://rest-assistant.api.cloud.yandex.net/v1\",\n",
    "    api_key=api_key,\n",
    "    project=folder_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94c653",
   "metadata": {},
   "source": [
    "Теперь создадим основной класс `Agent`, который позволит нам создавать агента, передавая ему:\n",
    "* Системный промпт `instruction`\n",
    "* Набор внешних инструментов `tools`\n",
    "* Набор документов для RAG `search_content`\n",
    "\n",
    "Агент при создании автоматически создаст поисковый индекс из документов, а при вызове отработает Function Calling и вернет ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "671fe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "class Agent():\n",
    "\n",
    "    def __init__(self,\n",
    "            name,\n",
    "            instruction, \n",
    "            tools = [], search_content = [], \n",
    "            model = model,\n",
    "            response_format = None\n",
    "            ):\n",
    "        self.user_sessions = {}\n",
    "        self.name = name\n",
    "        self.instruction = instruction\n",
    "        self.model = model\n",
    "        self.tool_map = { x.__name__ : x for x in tools if issubclass(x, BaseModel) }\n",
    "        self.tools = [\n",
    "            self._create_tool_annot(x) for x in tools\n",
    "        ]\n",
    "        self.response_format = response_format\n",
    "        self.vector_store = None\n",
    "        if search_content:\n",
    "            i=0\n",
    "            self.vector_store = client.vector_stores.create(name=f'rag_store_{self.name}')\n",
    "            for c in search_content:\n",
    "                f = client.files.create(\n",
    "                        purpose=\"assistants\",\n",
    "                        file = (f'rag_{self.name}_{i}.txt',io.BytesIO(c.encode(\"utf-8\")),'text/markdown'))\n",
    "                client.vector_stores.files.create(file_id=f.id, vector_store_id=self.vector_store.id)\n",
    "                print(f\" + Uploading rag_{self.name}_{i}.txt as id={f.id} to store={self.vector_store.id}\")\n",
    "                i+=1\n",
    "            self.tools.append({\n",
    "                \"type\" : \"file_search\",\n",
    "                \"vector_store_ids\" : [self.vector_store.id],\n",
    "                \"max_num_results\" : 5,\n",
    "            })\n",
    "            \n",
    "    def _create_tool_annot(self, x):\n",
    "        if issubclass(x, BaseModel):\n",
    "            return {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": x.__name__,\n",
    "                \"description\": x.__doc__,\n",
    "                \"parameters\": x.model_json_schema(),\n",
    "            }\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __call__(self, message, session_id='default',return_raw=False):\n",
    "        s = self.user_sessions.get(session_id,{ 'previous_response_id' : None, 'history' : [] })\n",
    "        s['history'].append({ 'role': 'user', 'content': message })\n",
    "        txt = None\n",
    "        if self.response_format:\n",
    "            txt = {\n",
    "                \"format\" : {\n",
    "                    \"type\" : \"json_schema\",\n",
    "                    \"name\" : \"struct_out\",\n",
    "                    \"schema\" : self.response_format.model_json_schema()\n",
    "                }\n",
    "            }\n",
    "        res = client.responses.create(\n",
    "            model = self.model,\n",
    "            store = True,\n",
    "            tools = self.tools,\n",
    "            instructions = self.instruction,\n",
    "            previous_response_id = s['previous_response_id'],\n",
    "            input = message,\n",
    "            text = txt\n",
    "        )\n",
    "        # Обрабатываем вызов локальных инструментов\n",
    "        tool_calls = [item for item in res.output if item.type == \"function_call\"]\n",
    "        if tool_calls:\n",
    "            s['history'].append({ 'role' : 'func_call', 'content' : res.output_text })\n",
    "            out = []\n",
    "            for call in tool_calls:\n",
    "                print(f\" + Обрабатываем: {call.name} ({call.arguments})\")\n",
    "                try:\n",
    "                    fn = self.tool_map[call.name]\n",
    "                    obj = fn.model_validate(json.loads(call.arguments))\n",
    "                    result = obj.process(session_id)\n",
    "                except Exception as e:\n",
    "                    result = f\"Ошибка: {e}\"\n",
    "                #print(f\" + Результат: {result}\")\n",
    "                out.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": call.call_id,\n",
    "                    \"output\": result\n",
    "                })\n",
    "                res = client.responses.create(\n",
    "                    model=self.model,\n",
    "                    input=out,\n",
    "                    tools=self.tools,\n",
    "                    previous_response_id=res.id,\n",
    "                    store=True\n",
    "                )\n",
    "        # MCP Approval Requests\n",
    "        mcp_approve = [ item for item in res.output if item.type == \"mcp_approval_request\"]\n",
    "        if mcp_approve:\n",
    "            res = client.responses.create(\n",
    "                model=self.model,\n",
    "                previous_response_id=res.id,\n",
    "                tools = self.tools,\n",
    "                input=[{\n",
    "                    \"type\": \"mcp_approval_response\",\n",
    "                    \"approve\": True,\n",
    "                    \"approval_request_id\": m.id\n",
    "                }\n",
    "                for m in mcp_approve\n",
    "                ])\n",
    "        s['previous_response_id'] = res.id\n",
    "        s['history'].append({ 'role' : 'assistant', 'content' : res.output_text })\n",
    "        self.user_sessions[session_id] = s\n",
    "        if return_raw:\n",
    "            return res\n",
    "        if self.response_format:\n",
    "            return self.response_format.model_validate_json(res.output_text)\n",
    "        else:\n",
    "            return res.output_text\n",
    "\n",
    "    def history(self, session_id='default'):\n",
    "        return self.user_sessions[session_id]['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ba960",
   "metadata": {},
   "source": [
    "Для решения нашей задачи будем моделировать поход в ресторан в реальной жизни. У нас будут следующие роли:\n",
    "\n",
    "* Агент-официант владеет информацией о меню ресторана, и может рекомендовать конкретное блюдо\n",
    "* Агент-сомелье умеет подбирать сочетания блюд и вина\n",
    "* Агент-хостесс принимает первоначальные предпочтения посетителя, и далее маршрутизирует диалог между другими агентами для решения задачи.\n",
    "\n",
    "Создадим этих агентов:\n",
    "\n",
    "## Агент-официант\n",
    "\n",
    "Для начала, создадим агента, который владеет меню нашего ресторана. Поскольку меню обычно невелико по объему, то закинем его в конекст агента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "000530c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Ты - официант в ресторане, который должен советовать посетителям блюда и отвечать \n",
    "на вопросы по меню. Меню приведено ниже в тройных обратных кавычках. Если в меню нет указанного блюда\n",
    " - напиши, что блюдо отсутствует в меню. Не придумывай ничего!\n",
    "Меню:\n",
    "```\n",
    "{fread('data/menu/food.md')}\n",
    "{fread('data/menu/drinks.md')}\n",
    "``` \n",
    "\"\"\"\n",
    "\n",
    "waiter = Agent(\n",
    "    'waiter',\n",
    "    instruction=prompt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21c0501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ливерная колбаса отсутствует в меню."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(waiter(\"Сколько стоит ливерная колбаса?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "366b7d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Самое дорогое вино — **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года, цена за бокал — **5200 рублей**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(waiter(\"Какое самое дорогое вино?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc311f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Самый дорогой стейк в меню — **\"Бык на взводе\"**, цена — **2500 рублей**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(waiter(\"Какой самый дорогой стейк в меню?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b7bc3",
   "metadata": {},
   "source": [
    "## Агент-сомелье\n",
    "\n",
    "Теперь создадим агента, который может дать рекомендации по сочетанию вин и еды. Будем использовать таблицу соответствий еды и вина такого вида:\n",
    "\n",
    "Блюдо, к которому надо подобрать вино | Вино, которое подходит к этому блюду\n",
    "--------|--------\n",
    "Баклажаны, запеченые с сыром | Красное вино: «среднетелые»* сухие — Гренаш (Гарнача), Санджовезе (Кьянти), Карменер, Менсия, молодые Темпранильо, легкотелое Мерло.\n",
    "Баранина деликатесная (филе или каре ягненка) | Красное вино: сухие выдержанные вина из винограда Пино Нуар, Менсия, Неббиоло (в том числе элегантные выдержанные Бароло и Барбареско), Гамэ (элегантные бургундские Божоле Виляж).\n",
    "Баранина пикантная: жареная, гриль, тушеная — со специями | Красные вина: сухие вина из винограда Каберне Совиньон, «ронские»** ассамбляжи Гренаш+Сира+Мурведр, французский Мальбек, немного «скругленная» Барбера, Сира (Шираз). Выдержанные вина из Санджовезе (Кьянти Классико, вина Монтальчино), Альянико, «супертосканские»*** вина, добротные Crianza Риохи. Примитиво и Зинфандель. Саперави из России.\n",
    "\n",
    "Для этого также используем RAG, как в предыдущем примере, только вручную нарежем табличку на небольшие фрагменты, обязательно содержащие в себе заголовок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/food_wine_table.md\", encoding=\"utf-8\") as f:\n",
    "    food_wine = f.readlines()\n",
    "header = food_wine[:2]\n",
    "chunk_size = 1000 * 3  # approx 1000 tokens * 3 char/token\n",
    "docs = []\n",
    "s = header.copy()\n",
    "for x in food_wine[2:]:\n",
    "    s.append(x)\n",
    "    if len(\"\".join(s)) > chunk_size:\n",
    "        docs.append(\"\".join(s))\n",
    "        s = header.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0662be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Uploading rag_sommelier_0.txt as id=fvtufb91gkfr47ffpcsh to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_1.txt as id=fvtidf78bglfnq7fgfsu to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_2.txt as id=fvthg8104nsgrq8uedjq to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_3.txt as id=fvtt7i3fa26msaqnh3d7 to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_4.txt as id=fvt0ao41eanhnrivppsl to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_5.txt as id=fvt2bv8mb6ci0a44ugl1 to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_6.txt as id=fvt87g7k2qbv3f4kns1r to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_7.txt as id=fvtuh90h9uulufq3d4lk to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_8.txt as id=fvtpl3j79bfh2vas933i to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_9.txt as id=fvtji6t7sfifvqm5mtnk to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_10.txt as id=fvtqc000aiuu7l40a7g5 to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_11.txt as id=fvtr2go79g5e0or3noqc to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_12.txt as id=fvt4fvqb92stsr24dbbf to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_13.txt as id=fvt8gvlgvu46jlqgriv3 to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_14.txt as id=fvtjpf5rtrc1mcur8aha to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_15.txt as id=fvtrpgnjh8mn4tekplrl to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_16.txt as id=fvtd7cg3e23q36bimike to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_17.txt as id=fvtlself4at05mjl5krf to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_18.txt as id=fvtkc1mdq9o35lgdi7jm to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_19.txt as id=fvtsf7udht2e66jdl29d to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_20.txt as id=fvtev2tcbph39gg0goji to store=fvtcmqftpc3i1r0608jj\n",
      " + Uploading rag_sommelier_21.txt as id=fvt7vrv8vinj58gkrcjo to store=fvtcmqftpc3i1r0608jj\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Ты - опытный сомелье, который должен рекомендовать клиенту правильные сочетания блюд и вина. Отвечай на просьба подобрать вино к еде или еду к вину, используя имеющуюся у тебя информацию. Также если\n",
    "пользователь просит посоветовать ему какое-то интересное сочетание - сделай это на основе имеющихся данных. Не придумывай ничего!\n",
    "\"\"\"\n",
    "\n",
    "sommelier = Agent(\n",
    "    'sommelier',\n",
    "    search_content=docs,\n",
    "    instruction=prompt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1d6843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Для стейка отлично подойдёт **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года. Это вино обладает насыщенным танинным каркасом, яркой кислотностью и богатым букетом, в котором переплетаются оттенки спелой вишни, табака, дуба и чёрного перца. Такое сочетание идеально дополняет вкус стейка, подчёркивая его сочность и глубину."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(sommelier(\"Какое вино подойдёт к стейку?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69cf4f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "К стейку **филе миньон** идеально подойдёт **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года. Это вино обладает утончённой структурой, нежной танинностью и сложным ароматическим букетом, включающим ноты вишни, красной смородины, фиалки и лёгкие древесные оттенки. Такое сочетание подчеркнёт нежность и изысканность филе миньон, не перебивая его тонкий вкус."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(sommelier(\"Какое вино подойдёт к стейку филе миньон?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c21f6",
   "metadata": {},
   "source": [
    "## Агент-хостесс\n",
    "\n",
    "На входе в ресторан посетителя приветствует хостесс, которая интересуется, что именно хочет есть человек. Для этого заведём специального агента, который будет вычленять из запроса пользователя его предпочтения по вину и по еде. Для этого используем структурный вывод модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a01bc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class PersonPref(BaseModel):\n",
    "    food_pref : str = \"\"\n",
    "    wine_pref : str = \"\"\n",
    "    \n",
    "prompt = \"\"\"\n",
    "Ты - официант в ресторане, задача которого принять заказ у посетителя.\n",
    "Тебе необходимо выслушать его и понять, есть ли у него какие-то предпочтения\n",
    "по еде или по вину. Верни ответ в формате json, с полями \n",
    "`food_pref` и `wine_pref`, в которых будут указаны предпочтения. \n",
    "Если нет предпочтений, то верни пустые строки.\n",
    "\"\"\"\n",
    "\n",
    "hostess = Agent(\n",
    "    'hostess',\n",
    "    instruction=prompt,\n",
    "    response_format=PersonPref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39b510c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PersonPref(food_pref='мясо', wine_pref='')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = hostess(\"Привет, я хочу поесть что-то из мяса\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845d317",
   "metadata": {},
   "source": [
    "## Собираем агентов вместе: LangGraph\n",
    "\n",
    "Для объединения агентов вместе будем использовать фреймворк LangGraph. В основе этого фреймворка - идея графа состояний (state machine) и **состояния**, в зависимости от которого определяется дальнейшее поведение системы.\n",
    "\n",
    "Узлами графа являются функции, которые возвращают **state update** - объект, который обновляет состояние. Для начала опишем класс, который будет определять состояние системы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48d41bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class RecommenderState(TypedDict):\n",
    "    message : str\n",
    "    foodpref : str = \"\"\n",
    "    winepref : str = \"\"\n",
    "    maindish : str\n",
    "    wine : str\n",
    "    answer : str\n",
    "    \n",
    "def pr(state: RecommenderState):\n",
    "    return ', '.join([f\"{k}={v}\" for k,v in state.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272cffd",
   "metadata": {},
   "source": [
    "Исходное сообщение пользователя будет в поле `message`, а финальный ответ - в поле `answer`. Начальные преференции пользователя будем хранить в полях `foodpref` и `winepref`, а выбранные блюдо и вино - в полях `maindish` и `wine`.\n",
    "\n",
    "Логика работы будет такая:\n",
    "* Вначале извлекаем предпочтения пользователя - за это отвечает функция `welcome` и агент-хостесс\n",
    "* Основным узлом-маршрутизатором нашей многоагентной системы будет функция `clarify`. Если она видит какие-то из преференций `foodpref` или `winepref` - она выбирает по ним соответствующие блюда из меню с помощью агента-официанта.\n",
    "* После `clarify` выполняется функция `route_user`, которая определяет, что делать дальше:\n",
    "   - Если блюда и вино выбраны - мы отправляемся в узел `check_combination`, где с помощью сомелье проверяем, насколько выбранные блюдо и вино сочетаются между собой. Они могут не сочетаться, если пользователь сразу захотел есть стейк с белым вином.\n",
    "   - Если какая-то из преференций `winepref` или `foodpref` не заполнены - происходит вызов функции `recommend_food` или `recommend_wine`, чтобы с помощью сомелье заполнить этот пробел\n",
    "   - Если у пользователя нет преференций, то функция `select_random` выбирает для него какое-то блюдо, после чего выполнение агента продолжается с узла `recommend_wine`.\n",
    "\n",
    "Помимо описания функций для каждого из узлов, нам нужно явным образом добавить узлы в граф с помощью `add_node`, и все переходы между ними, с помощью `add_edge` и `add_conditional_edges`. Дальше получишийся граф можно наприсовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40438356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "def welcome_user(state: RecommenderState):\n",
    "    print(f\"> Welcome, state={pr(state)}\")\n",
    "    msg = state['message']\n",
    "    print(f\" + Сообщение от пользователя: {msg}\")\n",
    "    res = hostess(msg)\n",
    "    print(f\" + Получены преференции: {res}\")\n",
    "    return {\n",
    "        'foodpref' : res.food_pref,\n",
    "        'winepref' : res.wine_pref\n",
    "    }\n",
    "    \n",
    "def route_user(state: RecommenderState) -> str:\n",
    "    if state.get('maindish') and state.get('wine'): return \"Done\"\n",
    "    if state['foodpref'] == \"\" and state['winepref'] == \"\": return \"None\"\n",
    "    elif state['foodpref'] == \"\" and state['winepref'] != \"\": return \"WantWine\"\n",
    "    elif state['foodpref'] != \"\" and state['winepref'] == \"\": return \"WantFood\"\n",
    "    else: return \"Both\"\n",
    "\n",
    "def select_random(state: RecommenderState):\n",
    "    print(f\"> SelectRandom, state={pr(state)}\")\n",
    "    maindish = waiter(\n",
    "        \"Порекомендуйте мне какое-нибудь одно основное блюдо. Напиши в ответ только название этого блюда.\")\n",
    "    print(f\" + Выбрано случайное блюдо: {maindish}\")\n",
    "    return { \"maindish\" : maindish }\n",
    "    \n",
    "def recommend_food(state: RecommenderState):\n",
    "    print(f\"> Recommend Food, state={pr(state)}\")\n",
    "    wine = state.get(\"wine\") or state.get(\"winepref\")\n",
    "    print(f\" + Рекомендуем блюда к вину {wine}\")\n",
    "    foodpref = sommelier(f\"Какие типы блюд подойдут к вину {wine}?\")\n",
    "    print(f\" + Рекомендации: {foodpref}\")\n",
    "    return { \"foodpref\" : foodpref }\n",
    "\n",
    "def recommend_wine(state: RecommenderState):\n",
    "    print(f\"> Recommend wine, state={pr(state)}\")\n",
    "    food = state.get('maindish') or state.get('foodpref')\n",
    "    print(f\" + Рекомендуем вино к блюду {food}\")\n",
    "    winepref = sommelier(f\"Какие вина подойдут к блюду {food}?\")\n",
    "    print(f\" + Рекомендации: {winepref}\")\n",
    "    return { \"winepref\" : winepref }\n",
    "    \n",
    "def clarify(state: RecommenderState):\n",
    "    print(f\"> Clarify, state={pr(state)}\")\n",
    "    upd = {}\n",
    "    if state.get(\"winepref\") and not state.get('wine'):\n",
    "        print(f\" + Подбираем вино: {state['winepref']}\")\n",
    "        upd[\"wine\"] = waiter(f\"Какое из следующих вин в меню подходит под такое описание: {state['winepref']}? Выбери только одно вино из меню.\")\n",
    "        print(f\" + Выбрано вино: {upd['wine']}\")\n",
    "    if state.get(\"foodpref\") and not state.get('maindish'):\n",
    "        print(f\" + Подбираем еду: {state['foodpref']}\")\n",
    "        upd[\"maindish\"] = waiter(f\"Какое из следующих блюд в меню подходит под такое описание: {state['foodpref']}?  Выбери только одно блюдо из меню.\")\n",
    "        print(f\" + Выбрано блюдо: {upd['maindish']}\")\n",
    "    return upd\n",
    "\n",
    "def check_combination(state: RecommenderState):\n",
    "    print(f\"> Check combination, state={pr(state)}\")\n",
    "    food = state[\"maindish\"]\n",
    "    wine = state[\"wine\"]\n",
    "    print(f\" + Проверяем сочетаемость блюда {food} и вина {wine}\")\n",
    "    res = sommelier(f\"Сочетается ли блюдо {food} с вином {wine}? Ответь ДА или НЕТ\")\n",
    "    if \"нет\" in res.lower():\n",
    "        ans = waiter(f\"Тебе хотят заказать следующее блюдо {state['maindish']} и вино {state['wine']}. Напиши вежливый ответ, что это блюдо и вино не очень сочетаются, и предложи выбрать другую комбинацию.\")\n",
    "    else:\n",
    "        ans = waiter(f\"Предложи гостям следующее блюдо {state['maindish']} и вино {state['wine']}.\")\n",
    "    return { \"answer\" : ans}\n",
    "\n",
    "def yes_or_no(state: RecommenderState):\n",
    "    if state[\"maindish\"] and state[\"wine\"]:\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "recommender_graph = StateGraph(RecommenderState)\n",
    "recommender_graph.add_node(\"Welcome\", welcome_user)\n",
    "recommender_graph.add_node(\"SelectRandom\", select_random)\n",
    "recommender_graph.add_node(\"RecommendFood\", recommend_food)\n",
    "recommender_graph.add_node(\"RecommendWine\", recommend_wine)\n",
    "recommender_graph.add_node(\"CheckCombination\", check_combination)\n",
    "recommender_graph.add_node(\"Clarify\", clarify)\n",
    "\n",
    "recommender_graph.add_edge(START, \"Welcome\")\n",
    "recommender_graph.add_edge(\"Welcome\", \"Clarify\")\n",
    "recommender_graph.add_conditional_edges(\n",
    "    \"Clarify\",\n",
    "    route_user,\n",
    "    {\n",
    "        \"None\": \"SelectRandom\",\n",
    "        \"WantWine\" : \"RecommendFood\",\n",
    "        \"WantFood\" : \"RecommendWine\",\n",
    "        \"Both\" : \"CheckCombination\",\n",
    "        \"Done\" : \"CheckCombination\"\n",
    "    })\n",
    "recommender_graph.add_edge(\"SelectRandom\", \"RecommendWine\")\n",
    "recommender_graph.add_edge(\"RecommendFood\", \"Clarify\")\n",
    "recommender_graph.add_edge(\"RecommendWine\", \"Clarify\")\n",
    "recommender_graph.add_edge(\"CheckCombination\", END)\n",
    "\n",
    "compiled_graph = recommender_graph.compile()\n",
    "\n",
    "#display(Image(compiled_graph.get_graph().draw_mermaid_png(max_retries=5,retry_delay=2.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173bd84f",
   "metadata": {},
   "source": [
    "Для того, чтобы \"поговорить\" с этой системой, дадим ей на вход начальное состояние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef211339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Welcome, state=message=Привет, я хочу поесть что-то из мяса\n",
      " + Сообщение от пользователя: Привет, я хочу поесть что-то из мяса\n",
      " + Получены преференции: food_pref='мясо' wine_pref=''\n",
      "> Clarify, state=message=Привет, я хочу поесть что-то из мяса, foodpref=мясо, winepref=\n",
      " + Подбираем еду: мясо\n",
      " + Выбрано блюдо: Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев.\n",
      "> Recommend wine, state=message=Привет, я хочу поесть что-то из мяса, foodpref=мясо, winepref=, maindish=Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев.\n",
      " + Рекомендуем вино к блюду Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев.\n",
      " + Рекомендации: К стейку **\"Бык на взводе\"** (сочному рибай с розовым сердцем) отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно идеально дополняет насыщенный вкус стейка.\n",
      "\n",
      "2. **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года — более утончённый выбор с нежной танинностью и ароматами вишни, красной смородины и фиалки. Подойдёт, если вы предпочитаете более изысканное и элегантное сочетание.\n",
      "\n",
      "Оба вина подчеркнут сочность и глубину вкуса стейка, но Каберне Совиньон — более классический и мощный выбор.\n",
      "> Clarify, state=message=Привет, я хочу поесть что-то из мяса, foodpref=мясо, winepref=К стейку **\"Бык на взводе\"** (сочному рибай с розовым сердцем) отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно идеально дополняет насыщенный вкус стейка.\n",
      "\n",
      "2. **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года — более утончённый выбор с нежной танинностью и ароматами вишни, красной смородины и фиалки. Подойдёт, если вы предпочитаете более изысканное и элегантное сочетание.\n",
      "\n",
      "Оба вина подчеркнут сочность и глубину вкуса стейка, но Каберне Совиньон — более классический и мощный выбор., maindish=Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев.\n",
      " + Подбираем вино: К стейку **\"Бык на взводе\"** (сочному рибай с розовым сердцем) отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно идеально дополняет насыщенный вкус стейка.\n",
      "\n",
      "2. **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года — более утончённый выбор с нежной танинностью и ароматами вишни, красной смородины и фиалки. Подойдёт, если вы предпочитаете более изысканное и элегантное сочетание.\n",
      "\n",
      "Оба вина подчеркнут сочность и глубину вкуса стейка, но Каберне Совиньон — более классический и мощный выбор.\n",
      " + Выбрано вино: Из представленных в меню вин, подходящих под описание, **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — это лучший выбор к стейку **\"Бык на взводе\"**.\n",
      "\n",
      "Он обладает насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца, что идеально дополняет насыщенный вкус сочного рибая.\n",
      "> Check combination, state=message=Привет, я хочу поесть что-то из мяса, foodpref=мясо, winepref=К стейку **\"Бык на взводе\"** (сочному рибай с розовым сердцем) отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно идеально дополняет насыщенный вкус стейка.\n",
      "\n",
      "2. **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года — более утончённый выбор с нежной танинностью и ароматами вишни, красной смородины и фиалки. Подойдёт, если вы предпочитаете более изысканное и элегантное сочетание.\n",
      "\n",
      "Оба вина подчеркнут сочность и глубину вкуса стейка, но Каберне Совиньон — более классический и мощный выбор., maindish=Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев., wine=Из представленных в меню вин, подходящих под описание, **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — это лучший выбор к стейку **\"Бык на взводе\"**.\n",
      "\n",
      "Он обладает насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца, что идеально дополняет насыщенный вкус сочного рибая.\n",
      " + Проверяем сочетаемость блюда Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев. и вина Из представленных в меню вин, подходящих под описание, **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — это лучший выбор к стейку **\"Бык на взводе\"**.\n",
      "\n",
      "Он обладает насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца, что идеально дополняет насыщенный вкус сочного рибая.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Привет, я хочу поесть что-то из мяса',\n",
       " 'foodpref': 'мясо',\n",
       " 'winepref': 'К стейку **\"Бык на взводе\"** (сочному рибай с розовым сердцем) отлично подойдут следующие вина:\\n\\n1. **Каберне Совиньон** от **Château de Parenchère, Франция**, 2017 года — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно идеально дополняет насыщенный вкус стейка.\\n\\n2. **Пино Нуар** от **Domaine de la Romanée-Conti, Франция**, 2017 года — более утончённый выбор с нежной танинностью и ароматами вишни, красной смородины и фиалки. Подойдёт, если вы предпочитаете более изысканное и элегантное сочетание.\\n\\nОба вина подчеркнут сочность и глубину вкуса стейка, но Каберне Совиньон — более классический и мощный выбор.',\n",
       " 'maindish': 'Под описание \"мясо\" лучше всего подходит **Стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, с золотой солью Гималаев.',\n",
       " 'wine': 'Из представленных в меню вин, подходящих под описание, **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — это лучший выбор к стейку **\"Бык на взводе\"**.\\n\\nОн обладает насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца, что идеально дополняет насыщенный вкус сочного рибая.',\n",
       " 'answer': 'Рекомендую вам попробовать **стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыму аргентинских страстей и поданный с золотой солью Гималаев. Это настоящий триумф вкуса и текстуры.\\n\\nВ паре с ним идеально сочетается **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно подчёркивает глубину и насыщенность стейка, создавая гармоничное и запоминающееся сочетание.\\n\\nПриятного аппетита!'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = compiled_graph.invoke(\n",
    "    {\n",
    "        \"message\" : \"Привет, я хочу поесть что-то из мяса\"\n",
    "    }\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f16b481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Рекомендую вам попробовать **стейк \"Бык на взводе\"** — сочный рибай с розовым сердцем, томлёный в дыму аргентинских страстей и поданный с золотой солью Гималаев. Это настоящий триумф вкуса и текстуры.\n",
       "\n",
       "В паре с ним идеально сочетается **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, яркой кислотностью и богатым букетом спелой вишни, табака, дуба и чёрного перца. Оно подчёркивает глубину и насыщенность стейка, создавая гармоничное и запоминающееся сочетание.\n",
       "\n",
       "Приятного аппетита!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c5817",
   "metadata": {},
   "source": [
    "Рассмотрим пример, когда пользователь хочет изначально не слишком хорошее сочетание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34328da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Welcome, state=message=Привет, я хочу съесть какое-то рыбное блюдо с мерло!\n",
      " + Сообщение от пользователя: Привет, я хочу съесть какое-то рыбное блюдо с мерло!\n",
      " + Получены преференции: food_pref='рыбное блюдо' wine_pref='мерло'\n",
      "> Clarify, state=message=Привет, я хочу съесть какое-то рыбное блюдо с мерло!, foodpref=рыбное блюдо, winepref=мерло\n",
      " + Подбираем вино: мерло\n",
      " + Выбрано вино: Вино, подходящее под описание \"Мерло\", — **Мерло от Marchesi Antinori, Италия, 2019 года**, цена за бокал — **2800 рублей**.\n",
      " + Подбираем еду: рыбное блюдо\n",
      " + Выбрано блюдо: Блюдо, подходящее под описание \"рыбное блюдо\", — **\"Лосось в мечтах о Норвегии\"**: нежнейшее филе-кусок, запечённое под корочкой из \"загадочных северных трав\" (укропа), с лимонным бризом.\n",
      "> Check combination, state=message=Привет, я хочу съесть какое-то рыбное блюдо с мерло!, foodpref=рыбное блюдо, winepref=мерло, maindish=Блюдо, подходящее под описание \"рыбное блюдо\", — **\"Лосось в мечтах о Норвегии\"**: нежнейшее филе-кусок, запечённое под корочкой из \"загадочных северных трав\" (укропа), с лимонным бризом., wine=Вино, подходящее под описание \"Мерло\", — **Мерло от Marchesi Antinori, Италия, 2019 года**, цена за бокал — **2800 рублей**.\n",
      " + Проверяем сочетаемость блюда Блюдо, подходящее под описание \"рыбное блюдо\", — **\"Лосось в мечтах о Норвегии\"**: нежнейшее филе-кусок, запечённое под корочкой из \"загадочных северных трав\" (укропа), с лимонным бризом. и вина Вино, подходящее под описание \"Мерло\", — **Мерло от Marchesi Antinori, Италия, 2019 года**, цена за бокал — **2800 рублей**.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Спасибо за интерес к нашему меню!  \n",
       "\n",
       "Блюдо **\"Лосось в мечтах о Норвегии\"** — это нежное, изысканное рыбное блюдо с лёгкой кислинкой лимона и ароматом укропа, и оно лучше всего раскрывается с белыми винами, например, с **Совиньон Блан от Cloudy Bay, Новая Зеландия, 2021 года** — его свежесть и цитрусовые нотки идеально дополнят вкус лосося.\n",
       "\n",
       "К сожалению, **Мерло от Marchesi Antinori** — это мягкое, но насыщенное красное вино с телесной структурой, которое может перебить тонкий вкус рыбы. Оно прекрасно сочетается с мясными блюдами, но с лососем — не лучший выбор.\n",
       "\n",
       "Позвольте предложить вам более гармоничную пару:  \n",
       "**\"Лосось в мечтах о Норвегии\"** + **Совиньон Блан (Cloudy Bay, 2021)** — это настоящий дуэт севера и свежести.\n",
       "\n",
       "Буду рад помочь с оформлением заказа!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = compiled_graph.invoke(\n",
    "    {\n",
    "        \"message\" : \"Привет, я хочу съесть какое-то рыбное блюдо с мерло!\"\n",
    "    }\n",
    ")\n",
    "printx(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f3c85",
   "metadata": {},
   "source": [
    "И наконец случай, когда у пользователя нет предпочтений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24568ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Welcome, state=message=Что вкусного есть у вас сегодня?\n",
      " + Сообщение от пользователя: Что вкусного есть у вас сегодня?\n",
      " + Получены преференции: food_pref='' wine_pref=''\n",
      "> Clarify, state=message=Что вкусного есть у вас сегодня?, foodpref=, winepref=\n",
      "> SelectRandom, state=message=Что вкусного есть у вас сегодня?, foodpref=, winepref=\n",
      " + Выбрано случайное блюдо: Стейк \"Бык на взводе\"\n",
      "> Recommend wine, state=message=Что вкусного есть у вас сегодня?, foodpref=, winepref=, maindish=Стейк \"Бык на взводе\"\n",
      " + Рекомендуем вино к блюду Стейк \"Бык на взводе\"\n",
      " + Рекомендации: К стейку **\"Бык на взводе\"** отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, глубоким букетом спелой вишни, табака, дуба и чёрного перца. Его структура идеально сбалансирована с сочной, дымной текстурой стейка.\n",
      "\n",
      "2. **Пино Нуар от Domaine de la Romanée-Conti, Франция, 2017 года** — более изысканный и элегантный выбор с нежными нотами вишни, фиалки и лёгкими древесными оттенками. Подойдёт, если вы предпочитаете более тонкое, но глубокое сочетание.\n",
      "\n",
      "Оба вина подчеркнут богатый вкус стейка, но **Каберне Совиньон от Château Lafite Rothschild** — наиболее гармоничный и классический выбор.\n",
      "> Clarify, state=message=Что вкусного есть у вас сегодня?, foodpref=, winepref=К стейку **\"Бык на взводе\"** отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, глубоким букетом спелой вишни, табака, дуба и чёрного перца. Его структура идеально сбалансирована с сочной, дымной текстурой стейка.\n",
      "\n",
      "2. **Пино Нуар от Domaine de la Romanée-Conti, Франция, 2017 года** — более изысканный и элегантный выбор с нежными нотами вишни, фиалки и лёгкими древесными оттенками. Подойдёт, если вы предпочитаете более тонкое, но глубокое сочетание.\n",
      "\n",
      "Оба вина подчеркнут богатый вкус стейка, но **Каберне Совиньон от Château Lafite Rothschild** — наиболее гармоничный и классический выбор., maindish=Стейк \"Бык на взводе\"\n",
      " + Подбираем вино: К стейку **\"Бык на взводе\"** отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, глубоким букетом спелой вишни, табака, дуба и чёрного перца. Его структура идеально сбалансирована с сочной, дымной текстурой стейка.\n",
      "\n",
      "2. **Пино Нуар от Domaine de la Romanée-Conti, Франция, 2017 года** — более изысканный и элегантный выбор с нежными нотами вишни, фиалки и лёгкими древесными оттенками. Подойдёт, если вы предпочитаете более тонкое, но глубокое сочетание.\n",
      "\n",
      "Оба вина подчеркнут богатый вкус стейка, но **Каберне Совиньон от Château Lafite Rothschild** — наиболее гармоничный и классический выбор.\n",
      " + Выбрано вино: Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года\n",
      "> Check combination, state=message=Что вкусного есть у вас сегодня?, foodpref=, winepref=К стейку **\"Бык на взводе\"** отлично подойдут следующие вина:\n",
      "\n",
      "1. **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года** — вино с насыщенным танинным каркасом, глубоким букетом спелой вишни, табака, дуба и чёрного перца. Его структура идеально сбалансирована с сочной, дымной текстурой стейка.\n",
      "\n",
      "2. **Пино Нуар от Domaine de la Romanée-Conti, Франция, 2017 года** — более изысканный и элегантный выбор с нежными нотами вишни, фиалки и лёгкими древесными оттенками. Подойдёт, если вы предпочитаете более тонкое, но глубокое сочетание.\n",
      "\n",
      "Оба вина подчеркнут богатый вкус стейка, но **Каберне Совиньон от Château Lafite Rothschild** — наиболее гармоничный и классический выбор., maindish=Стейк \"Бык на взводе\", wine=Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года\n",
      " + Проверяем сочетаемость блюда Стейк \"Бык на взводе\" и вина Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Позвольте предложить вам настоящий дуэт силы и элегантности — **стейк \"Бык на взводе\"**: сочный рибай с розовым сердцем, томлёный в дыму аргентинских страстей и поданный с золотой солью Гималаев.\n",
       "\n",
       "В идеальной паре с ним — **Каберне Совиньон от Château Lafite Rothschild, Франция, 2018 года**. Это вино с насыщенным танинным каркасом, глубоким ароматом спелой вишни, табака, дуба и чёрного перца создаёт гармоничное и мощное сочетание, подчёркивающее богатый вкус стейка.\n",
       "\n",
       "Приятного аппетита и вдохновлённого ужина!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = compiled_graph.invoke(\n",
    "    {\n",
    "        \"message\" : \"Что вкусного есть у вас сегодня?\"\n",
    "    }\n",
    ")\n",
    "printx(res['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9158f",
   "metadata": {},
   "source": [
    "## Тестируем качество ответов: RAGAS\n",
    "\n",
    "Для того, чтобы отлаживать и улучшать многоагентные и RAG-системы, необходимо научиться автоматически измерять какую-то меру качества ответа. Тестирование диалоговых систем - вещь непростая, по нескольким причинам:\n",
    "\n",
    "* Непонятно, как оценивать качество естественно-языкового ответа\n",
    "* Сложно тестировать многоступенчатый диалог (multi-turn conversation)\n",
    "\n",
    "Для решения этих проблем сущестует библиотека [RAGAS](https://ragas.io). Рассмотрим её использование на примере тестирования нашей системы.\n",
    "\n",
    "Возможны разные подходы к тестированию (которые поддерживаются RAGAS):\n",
    "* Мы вручную создаём датасет с вопросами и идеальными вариантами ответа\n",
    "* Мы создаём датасет вопросов, и проверяем их по некоторому набору критериев или с помощью LLM в качества арбитра (LLM as a Judge)\n",
    "* Датасет вопросов автоматически создаётся по текстовой базе знаний RAG. RAGAS содержит развитые средства генерации вопросов, включающие построение графа знаний и различные его трансформации для получения разнообразных и нетривиальных вопросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e0f9b",
   "metadata": {},
   "source": [
    "\n",
    "Рассмотрим первый подход. В этом случае нам понадобится датасет с вопросами-ответами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d5a72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': 'Я хочу съесть что-то из мяса',\n",
       "  'reference': 'Я рекомендую сочный стейк и терпкое красное вино, например, Мальбек или Мерло.'},\n",
       " {'user_input': 'По четвергам предпочитаю рыбу',\n",
       "  'reference': 'Я рекомендую рыбное блюдо, например, лосось на гриле, и сухое белое вино, например, Совиньон Блан или Рислинг.'},\n",
       " {'user_input': 'Я хочу съесть лосося с красным вином',\n",
       "  'reference': 'Сожалею, но мы не рекомендуем есть рыбу с красным вином.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ds = json.load(open('data/eval/evaluate_advisor.json','r'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000c314",
   "metadata": {},
   "source": [
    "Теперь возьмём этот датасет, запустим нашу многоагентную систему для каждого из вопросов, и запомним ответ в поле `response`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(ds):\n",
    "    print(f\"==== RUNNING EXAMPLE {i+1}: {x['user_input']}\")\n",
    "    res = compiled_graph.invoke(\n",
    "    {\n",
    "        \"message\" : x['user_input']\n",
    "    })\n",
    "    ds[i]['response'] = res['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cde9f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/eval/evaluate_advisor_results.json','w') as f:\n",
    "    json.dump(ds,f,indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dee529",
   "metadata": {},
   "source": [
    "Для ускорения демонстрации можно пропустить предыдущий шаг и сразу загрузить датасет с ответами системы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c8a13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': 'Я хочу съесть что-то из мяса',\n",
       "  'reference': 'Я рекомендую сочный стейк и терпкое красное вино, например, Мальбек или Мерло.',\n",
       "  'response': 'Стейк «Бык на взводе» — это сочный рибай с розовым сердцем, томлёный в дыме аргентинских страстей, который подаётся с золотой солью Гималаев. К этому блюду может отлично подойти вино Мерло от Marchesi Antinori, Италия. Это элегантное и выдержанное вино, которое хорошо сочетается со стейком. Цена стейка составляет 2500 рублей, а цена бокала вина — 2800 рублей.'},\n",
       " {'user_input': 'По четвергам предпочитаю рыбу',\n",
       "  'reference': 'Я рекомендую рыбное блюдо, например, лосось на гриле, и сухое белое вино, например, Совиньон Блан или Рислинг.',\n",
       "  'response': 'К вашему столу я могу предложить блюдо «Лосось в мечтах о Норвегии» — это нежный филе-кусок, запечённый под корочкой из «загадочных северных трав» (укропа), который подаётся с лимонным бризом. В качестве дополнения к этому блюду могу порекомендовать вино Совиньон Блан от Cloudy Bay, Новая Зеландия.'},\n",
       " {'user_input': 'Я хочу съесть лосося с красным вином',\n",
       "  'reference': 'Сожалею, но мы не рекомендуем есть рыбу с красным вином.',\n",
       "  'response': 'Спасибо за ваш выбор! К сожалению, «Лосось в мечтах о Норвегии» не очень хорошо сочетается с вином Мерло от Marchesi Antinori, Италия, 2019 года. Могу предложить вам другие варианты, которые, на мой взгляд, будут более удачным сочетанием. Например, к лососю подойдёт белое вино. Если вам нравится этот сорт рыбы, могу порекомендовать попробовать его с Шардоне от Louis Latour, Франция, 2020 года или с Совиньон Блан от Cloudy Bay, Новая Зеландия, 2021 года. Какой вариант вам больше по душе?'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = json.load(open('data/eval/evaluate_advisor_results.json','r'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785088b9",
   "metadata": {},
   "source": [
    "Теперь нам нужно оценить близость ответа системы к идеальному ответу. Для этого можно использовать текстовые эмбеддинги и метрику семантической близости. RAGAS позволяет нам использовать эмбеддинги из библиотеки LangChain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80aff769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitr\\AppData\\Local\\Temp\\ipykernel_65188\\4089688648.py:12: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  embeddings = LangchainEmbeddingsWrapper(embeddings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3066145add44d19f52f1f649cd05c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'answer_similarity': 0.7233}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import EvaluationDataset, SingleTurnSample\n",
    "from ragas import evaluate\n",
    "#from ragas.embeddings import OpenAIEmbeddings\n",
    "from ragas.metrics import answer_similarity\n",
    "from langchain_community.embeddings.yandex import YandexGPTEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "emodel = f\"emb://{folder_id}/text-search-query/latest\"\n",
    "\n",
    "#embeddings = OpenAIEmbeddings(aclient,model=emodel)\n",
    "embeddings = YandexGPTEmbeddings(folder_id=folder_id,iam_token=api_key)\n",
    "embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "tests = EvaluationDataset([ SingleTurnSample(**x) for x in ds ])\n",
    "evaluate(tests,[ answer_similarity ], embeddings=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6efa3",
   "metadata": {},
   "source": [
    "В RAGAS за проверку разных аспектов качества отвечают т.н. **метрики**. Выше мы использовали встроенную метрику `answer_similarity`, основанную на эмбеддингах.\n",
    "\n",
    "Второй вариант проверки ответов - это использование LLM as a Judge. Есть какое-то количество встроенных метрик с предопределёнными промптами (например, `AnswerAccuracy`), либо же можно определять свои метрики и задавать им промпты явно.\n",
    "\n",
    "Например, попробуем оценить правильность рекомендаций вина и еды в соответствии с простым правилом \"красное - к мясу, белое - к рыбе\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890819e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e160d52896644bc3921c927a38c7aa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'wine_food_match': 1.0000, 'nv_accuracy': 0.5000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yandex_cloud_ml_sdk import AsyncYCloudML\n",
    "from ragas.metrics import AspectCritic, AnswerAccuracy\n",
    "from ragas.llms import LangchainLLMWrapper,llm_factory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "#lc_client=OpenAI(\n",
    "#    model = model,\n",
    "#    base_url = \"https://rest-assistant.api.cloud.yandex.net/v1/\",\n",
    "#    api_key = api_key\n",
    "#)\n",
    "\n",
    "asdk = AsyncYCloudML(folder_id=folder_id,auth=api_key)\n",
    "judge_llm = LangchainLLMWrapper(asdk.models.completions(\"yandexgpt\", model_version=\"rc\").langchain())\n",
    "\n",
    "match_criteria = \"\"\"\n",
    "Подходит ли рекомендованное вино к блюду? Красные вина подходят к мясным блюдам,\n",
    "белые - к рыбным. Если пользователь хочет несочетаемую комбинацию - об этом\n",
    "нужно явно сказать в ответе, что такая комбинация не рекомендуется.\n",
    "\"\"\"\n",
    "wine_food_match = AspectCritic(\"wine_food_match\",match_criteria,llm=judge_llm)\n",
    "wine_food_match.async_mode=False\n",
    "answer_accuracy = AnswerAccuracy(llm=judge_llm)\n",
    "answer_accuracy.async_mode=False\n",
    "\n",
    "evaluate(tests,[ wine_food_match, answer_accuracy ], llm=judge_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cdddb",
   "metadata": {},
   "source": [
    "Установив таким образом механизм автоматического измерения и отслеживания метрик, мы теперь можем изменять параметры модели, экспериментировать с промптами и т.д. для оптимизации результата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96933bc",
   "metadata": {},
   "source": [
    "## Удаляем лишнее\n",
    "\n",
    "После демонстрации мы можем удалить все ассистенты, файлы, индексы и переписки.\n",
    "\n",
    "**ВНИМАНИЕ:** Код ниже удаляет все ассистенты, файлы, индексы и переписки в каталоге, с которым работает Yandex Cloud ML SDK. Если у вас есть другие проекты, использующие ассистентов, то лучше не выполняйте этот код, а дождитесь, когда объекты будут сами удалены по TTL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185f61c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Deleting vector store id=fvt2fnc2uaoters66s82\n",
      " + Deleting vector store id=fvtiqod24d1p7d7akla3\n",
      " + Deleting vector store id=fvtd69ju2e43u1ir70r5\n",
      " + Deleting vector store id=fvtf6j9kh6a72829g4ki\n",
      " + Deleting vector store id=fvtsi00cb7nofnt6dfq1\n",
      " + Deleting file id=fvthbunb4oiluq9lifgm\n",
      " + Deleting file id=fvtto04aemtvre337nbb\n",
      " + Deleting file id=fvttct3h4h17u9qq68tt\n",
      " + Deleting file id=fvt2m3skfa6sj2a0tg7k\n",
      " + Deleting file id=fvtrmqdl2f3bc8mf6anm\n",
      " + Deleting file id=fvt0q3cugcaa8egd0crk\n",
      " + Deleting file id=fvt6p32d9ms4cj1m9mg4\n",
      " + Deleting file id=fvt52b7umgta5ilceos6\n",
      " + Deleting file id=fvtbi1fr84q03dh2okal\n",
      " + Deleting file id=fvtsnnmhpecmntdgq608\n",
      " + Deleting file id=fvtbb609gqmfp0bn03e4\n",
      " + Deleting file id=fvtj7a8cnpgamsfotine\n",
      " + Deleting file id=fvt7fsg1geltt3top7e0\n",
      " + Deleting file id=fvt3jp1ulqemv4deosn8\n",
      " + Deleting file id=fvtimhsrcndl3eaiqpeb\n",
      " + Deleting file id=fvtvv498344lojnh50uh\n",
      " + Deleting file id=fvt5g1vur30uvq86qjpm\n",
      " + Deleting file id=fvtti0u5ov65p8ralpf6\n",
      " + Deleting file id=fvtuj4dh4c1nr8msgqva\n",
      " + Deleting file id=fvt4gv0t01s83j7tffne\n",
      " + Deleting file id=fvtar39oo1m7eg3mt9mv\n",
      " + Deleting file id=fvt321dgrv5iocmvp5la\n",
      " + Deleting file id=fvtmrubifonokh1rojt5\n",
      " + Deleting file id=fvt6c97hejopjho9qcg6\n",
      " + Deleting file id=fvth09459prap3r9vb6i\n",
      " + Deleting file id=fvthkibjm8emrgid1vjb\n",
      " + Deleting file id=fvtoln85313gfajsid7s\n",
      " + Deleting file id=fvtunp2vkobrcp7sk1c6\n",
      " + Deleting file id=fvtupmemgrgbpk7o7126\n",
      " + Deleting file id=fvtohl53moqtb2bfrmc0\n"
     ]
    }
   ],
   "source": [
    "vector_stores = client.vector_stores.list()\n",
    "for v in vector_stores:\n",
    "    print(f\" + Deleting vector store id={v.id}\")\n",
    "    client.vector_stores.delete(vector_store_id=v.id)\n",
    "\n",
    "files = client.files.list(purpose='assistants')\n",
    "for f in files:\n",
    "    print(f\" + Deleting file id={f.id}\")\n",
    "    client.files.delete(file_id=f.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f93e2",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "LangGraph - это фреймворк, позволяющий выстраивать заранее спланированные и управляемые графы взаимодействия между агентами. Это чуть более трудоёмко, зато мы контролируем процесс взаимодействия агентов, что часто бывает полезно при создании реальных систем."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
